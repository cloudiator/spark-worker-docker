#!/bin/bash

# include bpkg  dependencies
source /usr/local/bin/retry
source /usr/local/bin/bgo
source /usr/local/bin/bgowait

# global variables
GLOBAL_VAR="xyz"


##############################################################################
# validate if all container variables are set
##############################################################################
function validate(){

    # manadatory ENV vars
    vars="SPARK_MASTER_ENDPOINT SPARK_MASTER_PORT SPARK_WORKER_UI_PORT"
    for var in $vars; do
        if [[ $(env | awk -F "=" '{print $1}' | grep "^$var$") != "$var" ]]; then
            echo "$var not set but required."
            return 1
        fi
    done
    # optional ENV vars
    if [ -z "$JMS_IP" ]; 
	then
		echo "JMS_IP not set, falling back to default value"
        JMS_IP=localhost
    fi  

    if [ -z "$JMS_PORT" ]; 
	then
		echo "JMS_PORT not set, falling back to default value"
        JMS_PORT=61616
    fi  

    if [ -z "$APP_NAME" ]; 
	then
		echo "APP_NAME not set, falling back to default value"
        APP_NAME=dummyapp
    fi  

    if [ -z "$METRIC_PATTERN" ]; 
	then
		echo "METRIC_PATTERN not set, falling back to default value"
        METRIC_PATTERN={"metricValue":"\${metric.value}","timestamp":"\${metric.timestamp}","metricName":"\${metric.name}"}
    fi  

    if [ -z "$METRIC_REPORTING_INTERVAL" ]; 
	then
		echo "METRIC_REPORTING_INTERVAL not set, falling back to default value"
        METRIC_REPORTING_INTERVAL=30
    fi  

    # global ENV vars
    if [[ -z ${GLOBAL_VAR+x} ]]; then
        echo "GLOBAL_VAR variable cannot be looked up."
        return 1
    fi       
}

##############################################################################
# write config vars with configfile template
##############################################################################
function writeConfigOptions(){
    echo "write config options"
    export SPARK_MASTER_ENDPOINT=$SPARK_MASTER_ENDPOINT
    export SPARK_MASTER_PORT=$SPARK_MASTER_PORT
    export SPARK_WORKER_UI_PORT=$SPARK_WORKER_UI_PORT

    export JMS_IP=$JMS_IP
    export JMS_PORT=$JMS_PORT
    export APP_NAME=$APP_NAME
    export PUBLIC_ADDRESS=$PUBLIC_IP
    export METRIC_PATTERN=$METRIC_PATTERN
    export METRIC_REPORTING_INTERVAL=$METRIC_REPORTING_INTERVAL

    export SPARK_VERSION=2.3.1 
    export LOCAL_ADDRESS=$(ip route get 8.8.8.8 | awk '{print $NF; exit}')
    export PUBLIC_ADDRESS=$(dig +short myip.opendns.com @resolver1.opendns.com)
        
    #cat /opt/docker-conf/livy.conf | envsubst > /opt/spark-2.3.1-bin-hadoop2.7/livy.conf
    #TODO use envsubst if env vars are passed to the entrypoint
    cp /opt/docker-conf/log4j.properties /opt/spark-$SPARK_VERSION-bin-hadoop2.7/conf/log4j.properties
    cp /opt/docker-conf/spark-defaults.conf /opt/spark-$SPARK_VERSION-bin-hadoop2.7/conf/spark-defaults.conf
    cp /opt/docker-conf/spark-env.sh /opt/spark-$SPARK_VERSION-bin-hadoop2.7/conf/spark-env.sh
}

function init(){

    ## pre-config initialization

    # write file based config options
    writeConfigOptions

   

    ## post-config initialization

    ##TODO: check for Apache Spark if its running
}

##############################################################################



function spark_worker_service(){

    export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
   
    echo "SPARK_PUBLIC_DNS=$PUBLIC_ADDRESS"  >> /opt/spark-$SPARK_VERSION-bin-hadoop2.7/conf/spark-env.sh
    echo "SPARK_LOCAL_IP=$LOCAL_ADDRESS"  >> /opt/spark-$SPARK_VERSION-bin-hadoop2.7/conf/spark-env.sh
    echo "SPARK_MASTER_HOST=$LOCAL_ADDRESS"  >> /opt/spark-$SPARK_VERSION-bin-hadoop2.7/conf/spark-env.sh
    
    echo "starting Spark Worker!"
    /opt/spark-$SPARK_VERSION-bin-hadoop2.7/sbin/start-slave.sh  spark://$SPARK_MASTER_ENDPOINT:$SPARK_MASTER_PORT --webui-port $SPARK_WORKER_UI_PORT

    # whatever blocking call 
    tail -f /dev/null
}

function metric_agent_service(){

    # Set Spark Master Metrics Endpoint    
    echo -e "\ncollector.url=http://$LOCAL_ADDRESS:4040\n" >> /opt/metric-agent/metric.generator.properties
    
    # Set JMS Endpoint
    echo -e "jms.server.address=tcp://$JMS_IP\n" >> /opt/metric-agent/metric.generator.properties
    echo -e "jms.sever.port=$JMS_PORT\n" >> /opt/metric-agent/metric.generator.properties
    echo -e "collector.url.application.name=$APP_NAME\n" >> /opt/metric-agent/metric.generator.properties
    echo -e "metric.pattern=$METRIC_PATTERN\n" >> /opt/metric-agent/metric.generator.properties
    echo -e "collector.checking.time=$METRIC_REPORTING_INTERVAL\n" >> /opt/metric-agent/metric.generator.properties 

    java -jar /opt/metric-agent/metric-agent.jar -p /opt/metric-agent/metric.generator.properties

}

function start(){

    bgo spark_worker_service metric_agent_service
    if [[ $? != 0 ]]; then
        echo "start failed. exiting now." >&2
        exit 1
    fi
}

##############################################################################
function configure(){
    echo "configure: ..."
    ## post-start configuration via service
}

##############################################################################
function main(){
    # validate env vars
    validate
    if [[ $? != 0 ]]; then 
        echo "validation failed. exiting now." >&2
        exit 1
    fi

    # initialize
    init
    if [[ $? != 0 ]]; then 
        echo "init failed. exiting now." >&2
        exit 1
    fi

    # start
    start 
    if [[ $? != 0 ]]; then
        echo "start failed. exiting now." >&2
        exit 1
    fi    

    # configure
    retry 5 5 "configure failed." configure
    if [[ $? != 0 ]]; then
        echo "cannot run configure." >&2
        exit 1
    fi

    # wait
    echo "done. now waiting for services."
    #freq=5; waitForN=-1; killTasks=0 # fail one, ignore (development mode)
    freq=5; waitForN=1; killTasks=1 #fail one, fail all (production mode)
    bgowait $freq $waitForN $killTasks
}

if [[ "$1" == "" ]]; then
    main
else
    exec "$@"
fi
